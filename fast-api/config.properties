#!/bin/bash

# specify which Inferentia architecture to build for
# this is for naming only
docker_image_inf_type=inf2

# Docker Image and Container Name
docker_image_name_prefix=bert-${docker_image_inf_type}
docker_container_name_prefix=bert-${docker_image_inf_type}

# specify region here
region_name=us-east-1

# Deployment Setup
# Change the following based on paths and instance and AMI types

# For default Ubuntu DLAMI type uncomment this
# path_to_traced_models=/home/ubuntu/best-practices-for-fastapi-on-inferentia/traced-models-${docker_image_inf_type}
# path_to_tracing_code=/home/ubuntu/best-practices-for-fastapi-on-inferentia/tracing-${docker_image_inf_type}

# For AL2023 
path_to_tracing_code=/home/ec2-user/best-practices-for-fastapi-on-inferentia/tracing-${docker_image_inf_type}

# Name of the compiled model; This will be the name of the resulting TorchScript .pt file
# Change this based on 
compiled_model=$tracing-{docker_image_inf_type}/compiled-model-1.pt
num_cores=2
num_models_per_server=2
